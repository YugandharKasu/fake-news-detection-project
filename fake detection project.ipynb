{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27260965-efcc-4b3d-ba7c-43defa69bfd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0   id                domain        type  \\\n",
      "0           0  141               awm.com  unreliable   \n",
      "1           1  256     beforeitsnews.com        fake   \n",
      "2           2  700           cnnnext.com  unreliable   \n",
      "3           3  768               awm.com  unreliable   \n",
      "4           4  791  bipartisanreport.com   clickbait   \n",
      "\n",
      "                                                 url  \\\n",
      "0  http://awm.com/church-congregation-brings-gift...   \n",
      "1  http://beforeitsnews.com/awakening-start-here/...   \n",
      "2  http://www.cnnnext.com/video/18526/never-hike-...   \n",
      "3  http://awm.com/elusive-alien-of-the-sea-caught...   \n",
      "4  http://bipartisanreport.com/2018/01/21/trumps-...   \n",
      "\n",
      "                                             content  \\\n",
      "0  Sometimes the power of Christmas will make you...   \n",
      "1  AWAKENING OF 12 STRANDS of DNA – “Reconnecting...   \n",
      "2  Never Hike Alone: A Friday the 13th Fan Film U...   \n",
      "3  When a rare shark was caught, scientists were ...   \n",
      "4  Donald Trump has the unnerving ability to abil...   \n",
      "\n",
      "                   scraped_at                 inserted_at  \\\n",
      "0  2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n",
      "1  2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n",
      "2  2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n",
      "3  2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n",
      "4  2018-01-25 16:17:44.789555  2018-02-02 01:19:41.756632   \n",
      "\n",
      "                   updated_at  \\\n",
      "0  2018-02-02 01:19:41.756664   \n",
      "1  2018-02-02 01:19:41.756664   \n",
      "2  2018-02-02 01:19:41.756664   \n",
      "3  2018-02-02 01:19:41.756664   \n",
      "4  2018-02-02 01:19:41.756664   \n",
      "\n",
      "                                               title          authors  \\\n",
      "0  Church Congregation Brings Gift to Waitresses ...      Ruth Harris   \n",
      "1  AWAKENING OF 12 STRANDS of DNA – “Reconnecting...     Zurich Times   \n",
      "2  Never Hike Alone - A Friday the 13th Fan Film ...              NaN   \n",
      "3  Elusive ‘Alien Of The Sea ‘ Caught By Scientis...  Alexander Smith   \n",
      "4  Trump’s Genius Poll Is Complete & The Results ...  Gloria Christie   \n",
      "\n",
      "   keywords meta_keywords                                   meta_description  \\\n",
      "0       NaN          ['']                                                NaN   \n",
      "1       NaN          ['']                                                NaN   \n",
      "2       NaN          ['']  Never Hike Alone: A Friday the 13th Fan Film  ...   \n",
      "3       NaN          ['']                                                NaN   \n",
      "4       NaN          ['']                                                NaN   \n",
      "\n",
      "  tags  summary  \n",
      "0  NaN      NaN  \n",
      "1  NaN      NaN  \n",
      "2  NaN      NaN  \n",
      "3  NaN      NaN  \n",
      "4  NaN      NaN  \n"
     ]
    }
   ],
   "source": [
    "# Assistant\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "import os\n",
    "\n",
    "# Check if file exists, if not download it\n",
    "if not os.path.exists('fake_or_real_news.csv'):\n",
    "    print(\"File not found. Downloading...\")\n",
    "    # Updated URL to a working source for the dataset\n",
    "    url = \"https://raw.githubusercontent.com/several27/FakeNewsCorpus/master/news_sample.csv\"\n",
    "    # Alternatively, you could use another reliable source like Kaggle or UCI ML Repository\n",
    "    urllib.request.urlretrieve(url, 'fake_or_real_news.csv')\n",
    "    \n",
    "# Now read the file\n",
    "df = pd.read_csv('fake_or_real_news.csv')\n",
    "\n",
    "# Display the first few rows to verify the data loaded correctly\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f7ffc1c-e606-49b7-8bc7-f3dc22268282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (4, 8)\n",
      "Testing data shape: (1, 8)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Option 2: Create sample data directly instead of loading from a non-existent file\n",
    "# This avoids the FileNotFoundError since we're not trying to read a file\n",
    "data = [\"This is the first document.\", \"This document is the second document.\", \"And this is the third one.\", \n",
    "        \"Is this the first document?\", \"The last document.\"]\n",
    "labels = [0, 1, 2, 0, 1]  # Example labels\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Now apply TF-IDF vectorization\n",
    "# Increased max_df to 0.95 and removed stop_words for this small dataset\n",
    "vectorizer = TfidfVectorizer(max_df=0.95)  # Removed stop_words and increased max_df\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Print shapes to verify everything worked\n",
    "print(f\"Training data shape: {X_train_tfidf.shape}\")\n",
    "print(f\"Testing data shape: {X_test_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d43dd73-1c31-488a-b880-f50fa76f59b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "Confusion Matrix:\n",
      " [[0 0]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "model = PassiveAggressiveClassifier()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "49747571-a62d-4e98-96db-022529513c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, render_template\n",
    "import pickle\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the model and vectorizer\n",
    "# Note: Make sure these files exist in the correct path\n",
    "try:\n",
    "    model = pickle.load(open('model.pkl', 'rb'))\n",
    "    vectorizer = pickle.load(open('vectorizer.pkl', 'rb'))\n",
    "except FileNotFoundError:\n",
    "    print(\"Warning: model.pkl or vectorizer.pkl not found. This will cause errors when making predictions.\")\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    news = request.form['news']\n",
    "    data = vectorizer.transform([news])\n",
    "    prediction = model.predict(data)\n",
    "    return render_template('index.html', prediction_text=\"REAL\" if prediction else \"FAKE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668ae0b9-a2d0-4670-b2a0-28124924ee9b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
